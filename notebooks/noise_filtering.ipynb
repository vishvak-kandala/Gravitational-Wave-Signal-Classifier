{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cfaebc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import cv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import requests\n",
    "import gdown\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3aadd2",
   "metadata": {},
   "source": [
    "# Load data and generate spectrogram functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e812571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_strain_data(file_path):\n",
    "    with h5py.File(file_path, \"r\") as h:\n",
    "        strain = h[\"strain\"][\"Strain\"][:]\n",
    "    return strain\n",
    "\n",
    "\n",
    "def generate_spectrogram(hdf5_file):\n",
    "    strain_data = load_strain_data(hdf5_file)\n",
    "    frequency, time, spectrogram_array = spectrogram(strain_data, fs=4096)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    s_scaled = scaler.fit_transform(spectrogram_array)\n",
    "\n",
    "    return s_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ef4e6670",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_url = 'https://drive.google.com/drive/u/0/folders/1_ZEDaANx7ywRjHQm7A6EZZTGSc-0Jj_u'\n",
    "gdown.download_folder(folder_url, quiet=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e244e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Might possibly have some issues with where google drive downloads and github but works fine locally\n",
    "hdf5_dataset = pd.read_csv('/data/raw/D_files.csv')\n",
    "hdf5_dataset['Filename'] = \"/raw_strain_data/\" + hdf5_dataset['Filename'] \n",
    "hdf5_dataset['Category'] = hdf5_dataset['Category'].replace({'Event': 1, 'Non-Event': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e065b2",
   "metadata": {},
   "source": [
    "# Image feature extraction model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "42d14ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "def spectrogram_feature_extraction(spectrogram_array):\n",
    "    resized_spectrogram = cv2.resize(spectrogram_array, (224, 224))\n",
    "    final_spectrogram = np.stack([resized_spectrogram] * 3, axis=-1)\n",
    "    print(final_spectrogram.shape)\n",
    "    img_array = final_spectrogram[None, ...]\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    features = model.predict(img_array)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8232f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "C:\\Users\\erict\\anaconda3\\envs\\ml_eric_py310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:718: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "(224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    }
   ],
   "source": [
    "features_list = []\n",
    "for hdf5_file in hdf5_dataset['Filename']:\n",
    "    spec_data = generate_spectrogram(hdf5_file)\n",
    "    features = spectrogram_feature_extraction(spec_data).flatten()\n",
    "    features_list.append(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace6d3b",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9295732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# Not nearly enough datapoints to get anything accurate. Files are too large and it would take too long to extract features.\n",
    "# Only 20 datapoints used. Need more for training and testing the model\n",
    "\n",
    "X = np.array(features_list)\n",
    "y = hdf5_dataset['Category'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_eric_py310",
   "language": "python",
   "name": "ml_eric_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
